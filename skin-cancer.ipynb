{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el dataset\n",
    "1. Cargar el dataset que son imagenes que están dentro de carpetas separadas por test y train y cada una separada por maligno y benigno.\n",
    "2. Crearemos un dataset en el que por cada fila se incluye el path y si es benigno o maligno.\n",
    "3. Tenemos 4000 imagenes para el train y 2000 para el test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe train\n",
    "Obtener todas las imágenes dentro de la carpeta de train y guardar los Path junto con los nombres de las imagenes y si es maligna o benigna en un Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3999\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Train\n",
    "def train_df(train_path):\n",
    "    classes = [] # Benignas o malignas\n",
    "    class_paths = [] # Paths de las imagenes\n",
    "    image_names = [] # Nombre de las imagenes\n",
    "\n",
    "    # Obtener el contenido de la carpeta Train (Benigna y Maligna)\n",
    "    files = os.listdir(train_path)\n",
    "    for file in files: \n",
    "        label_dir = os.path.join(train_path, file)\n",
    "        label = os.listdir(label_dir)\n",
    "\n",
    "        # Obtener el contenido de la carpeta Benigna y Maligna (Imagenes)\n",
    "        for image in label:\n",
    "            if not image.startswith('.'): # Descartar ficheros ocultos\n",
    "                image_names.append(image) \n",
    "                class_paths.append(label_dir) \n",
    "                classes.append(file) \n",
    "\n",
    "    # Crear el dataframe\n",
    "    class_paths = pd.Series(class_paths, name='Class Path')\n",
    "    image_names = pd.Series(image_names, name='Image name')\n",
    "    image_classes = pd.Series(classes, name='Class') \n",
    "    tr_df = pd.concat([class_paths, image_names, image_classes], axis=1)\n",
    "    \n",
    "    return tr_df\n",
    "\n",
    "tr_df = train_df('./skin-cancer-dataset/train')\n",
    "print(len(tr_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe test\n",
    "Obtener todas las imágenes dentro de la carpeta de test y guardar los Path junto con los nombres de las imagenes y si es maligna o benigna en un Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "def test_df(test_path):\n",
    "    classes = [] # Benignas o malignas\n",
    "    class_paths = [] # Ruta a las imagenes\n",
    "    image_names = [] # Nombre de las imagenes\n",
    "\n",
    "    files = os.listdir(test_path) # Archivos\n",
    "    for file in files: \n",
    "        label_dir = os.path.join(test_path, file) # Path del directorio\n",
    "        label = os.listdir(label_dir) # Imagenes dentro del directorio\n",
    "        for image in label:\n",
    "            if not image.startswith('.'):\n",
    "                image_names.append(image) \n",
    "                class_paths.append(label_dir) \n",
    "                classes.append(file) # Añade el nombre del archivo\n",
    "\n",
    "    # Series de pandas\n",
    "    class_paths = pd.Series(class_paths, name='Class Path')\n",
    "    image_names = pd.Series(image_names, name='Image name')\n",
    "    image_classes = pd.Series(classes, name='Class') \n",
    "\n",
    "    # Crea el dataframe\n",
    "    ts_df = pd.concat([class_paths, image_names, image_classes], axis=1)\n",
    "    return ts_df\n",
    "\n",
    "ts_df = test_df('./skin-cancer-dataset/test')\n",
    "print(len(ts_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar los datos entre 0 y 1\n",
    "Normalizar los datos de Benigno y Maligno de string a numeros (0 o 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Class Path Image name  Class\n",
      "0     ./skin-cancer-dataset/train/Malignant     63.jpg      1\n",
      "1     ./skin-cancer-dataset/train/Malignant    823.jpg      1\n",
      "2     ./skin-cancer-dataset/train/Malignant   1409.jpg      1\n",
      "3     ./skin-cancer-dataset/train/Malignant    189.jpg      1\n",
      "4     ./skin-cancer-dataset/train/Malignant     77.jpg      1\n",
      "...                                     ...        ...    ...\n",
      "3994     ./skin-cancer-dataset/train/Benign    190.jpg      0\n",
      "3995     ./skin-cancer-dataset/train/Benign   1404.jpg      0\n",
      "3996     ./skin-cancer-dataset/train/Benign   1410.jpg      0\n",
      "3997     ./skin-cancer-dataset/train/Benign    184.jpg      0\n",
      "3998     ./skin-cancer-dataset/train/Benign   1376.jpg      0\n",
      "\n",
      "[3999 rows x 3 columns]                                 Class Path Image name  Class\n",
      "0     ./skin-cancer-dataset/test/Malignant   6400.jpg      1\n",
      "1     ./skin-cancer-dataset/test/Malignant   6366.jpg      1\n",
      "2     ./skin-cancer-dataset/test/Malignant   6372.jpg      1\n",
      "3     ./skin-cancer-dataset/test/Malignant   6414.jpg      1\n",
      "4     ./skin-cancer-dataset/test/Malignant   5653.jpg      1\n",
      "...                                    ...        ...    ...\n",
      "1995     ./skin-cancer-dataset/test/Benign   6343.jpg      0\n",
      "1996     ./skin-cancer-dataset/test/Benign   6425.jpg      0\n",
      "1997     ./skin-cancer-dataset/test/Benign   7075.jpg      0\n",
      "1998     ./skin-cancer-dataset/test/Benign   7061.jpg      0\n",
      "1999     ./skin-cancer-dataset/test/Benign   6419.jpg      0\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "tr_df['Class'].replace({'Benign': 0, 'Malignant': 1}, inplace=True)\n",
    "ts_df['Class'].replace({'Benign': 0, 'Malignant': 1}, inplace=True) \n",
    "print(tr_df, ts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferenciar los datos\n",
    "### Partir las X Y\n",
    "Indicar al Dataframe train y test cuales son los datos y cuales son los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainX = tr_df.values[:, :-1]\n",
    "trainY = tr_df.values[:, -1]\n",
    "\n",
    "# Test\n",
    "testX = ts_df.values[:, :-1]\n",
    "testY = ts_df.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir les Y en tensor\n",
    "Les X las convertimos despues de obtener la imagen del Path en el Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "trainY = torch.tensor(trainY.astype(int))\n",
    "testY = torch.tensor(testY.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase Dataset\n",
    "Al obtener el dataset devolverá la imagen como tensor, que será la X y los resultados Y.\n",
    "\n",
    "### **Normalizar las imagenes**:\n",
    "Las imágenes están contenidas dentro de X en forma de Path por un lado y el image name por otro. Para ello tenemos que convertir los paths a una imagen y normalizar los datos para que sean entre 0 y 1 en vez de 0 a 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as transform\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.image_path = X[:, 0]\n",
    "        self.image_name = X[:, 1]\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        PIL_image = PIL.Image.open(str(Path(self.image_path[idx]) / self.image_name[idx]))\n",
    "        tensor_image = transform.to_tensor(PIL_image)/255.0 # Convertir a tensor y normalizar\n",
    "    \n",
    "        return tensor_image, self.Y[idx] # Lo devuelves directamente como una imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear el propi dataset\n",
    "Passar al train_dataloader i test_dataloader un objecte dataset, nosaltres hem de crear aquet dataset extenent de la clase Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = myDataset(trainX, trainY)\n",
    "test_dataset = myDataset(testX, testY)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear la red neuronal\n",
    "1. Crear el dispositivo\n",
    "2. Definir la clase *Module* con la función forward\n",
    "    - Convulacional (como es en color, cada imagen se multiplica x 3)\n",
    "    - Capas normales \n",
    "3. Crear el modelo y pasarlo a la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Ya están implementadas las clases de las capas para hacer el forward\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # 3 imatges de 224 x 224\n",
    "            nn.Conv2d(3, 30, (8, 8)), # Entrada, salida, filtro\n",
    "            nn.MaxPool2d((4, 4)), \n",
    "\n",
    "            nn.Conv2d(30, 120, (5, 5)), # 120 imatges de 69x76\n",
    "            nn.MaxPool2d((3, 3)), # 120 imatges de 23x25\n",
    "\n",
    "            nn.Conv2d(120, 240, (3, 3)), # 250 imatges de 19x21\n",
    "            nn.MaxPool2d((3, 3)), # 250 imatges de 6x7\n",
    "            \n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(3840, 1000), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x) # Crea las capas\n",
    "        return logits\n",
    "    \n",
    "# Device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = NeuralNetwork().to(device) # Otiene los valores predichos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train y test\n",
    "Definimos las funciones para train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "def train_loop(train_dataloader, model, loss_fn, optimizer):\n",
    "    size = len(train_dataloader.dataset)\n",
    "\n",
    "    for batch, (X, Y) in enumerate(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        Y = nn.functional.one_hot(Y, num_classes=2) # One hot\n",
    "        Y = Y.to(device).to(torch.float32) # Float32 para trabajar con la GPU\n",
    "        \n",
    "        pred = model(X) # Forward, ya ha calculado todos los gradientes\n",
    "        loss = loss_fn(pred, Y) # Crear la función de costo: error\n",
    "\n",
    "        loss.backward() # Le pasa el error al gradiente\n",
    "        optimizer.step() # Actualiza los valores\n",
    "        optimizer.zero_grad() # Pone el gradiente a 0\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(test_dataloader, model, loss_fn):\n",
    "    size = len(test_dataloader.dataset)\n",
    "    num_batches = len(test_dataloader)\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # No calcula el gradiente automaticamente\n",
    "    with torch.no_grad():\n",
    "        for X, Y in test_dataloader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            pred = model(X) # Forward\n",
    "            test_loss += loss_fn(pred, Y).item() # Error\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item() # Accuracy\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llamar a train y test\n",
    "En cada epoca hacer un train y un test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.644680  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 2238653.125000 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4477131.000000  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 5354.986603 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 9955.676758  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.712359 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.939420  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.697529 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.820459  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.696152 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.803148  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.695544 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.794447  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.695254 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.789963  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.695107 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.787598  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.695029 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.786315  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.694986 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
