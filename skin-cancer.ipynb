{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el dataset\n",
    "1. Cargar el dataset que son imagenes que están dentro de carpetas separadas por test y train y cada una separada por maligno y benigno.\n",
    "2. Crearemos un dataset en el que por cada fila se incluye el path y si es benigno o maligno.\n",
    "3. Tenemos 4000 imagenes para el train y 2000 para el test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe train\n",
    "Obtener todas las imágenes dentro de la carpeta de train y guardar los Path junto con los nombres de las imagenes y si es maligna o benigna en un Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Class Path Image name      Class\n",
      "0     ./skin-cancer-dataset/train/Malignant     63.jpg  Malignant\n",
      "1     ./skin-cancer-dataset/train/Malignant    823.jpg  Malignant\n",
      "2     ./skin-cancer-dataset/train/Malignant   1409.jpg  Malignant\n",
      "3     ./skin-cancer-dataset/train/Malignant    189.jpg  Malignant\n",
      "4     ./skin-cancer-dataset/train/Malignant     77.jpg  Malignant\n",
      "...                                     ...        ...        ...\n",
      "3994     ./skin-cancer-dataset/train/Benign    190.jpg     Benign\n",
      "3995     ./skin-cancer-dataset/train/Benign   1404.jpg     Benign\n",
      "3996     ./skin-cancer-dataset/train/Benign   1410.jpg     Benign\n",
      "3997     ./skin-cancer-dataset/train/Benign    184.jpg     Benign\n",
      "3998     ./skin-cancer-dataset/train/Benign   1376.jpg     Benign\n",
      "\n",
      "[3999 rows x 3 columns]\n",
      "           Class Path  Image name\n",
      "Class                            \n",
      "Benign           2000        2000\n",
      "Malignant        1999        1999\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Train\n",
    "def train_df(train_path):\n",
    "    classes = [] # Benignas o malignas\n",
    "    class_paths = [] # Paths de las imagenes\n",
    "    image_names = [] # Nombre de las imagenes\n",
    "\n",
    "    # Obtener el contenido de la carpeta Train (Benigna y Maligna)\n",
    "    files = os.listdir(train_path)\n",
    "    for file in files: \n",
    "        label_dir = os.path.join(train_path, file)\n",
    "        label = os.listdir(label_dir)\n",
    "\n",
    "        # Obtener el contenido de la carpeta Benigna y Maligna (Imagenes)\n",
    "        for image in label:\n",
    "            if not image.startswith('.'): # Descartar ficheros ocultos\n",
    "                image_names.append(image) \n",
    "                class_paths.append(label_dir) \n",
    "                classes.append(file) \n",
    "\n",
    "    # Crear el dataframe\n",
    "    class_paths = pd.Series(class_paths, name='Class Path')\n",
    "    image_names = pd.Series(image_names, name='Image name')\n",
    "    image_classes = pd.Series(classes, name='Class') \n",
    "    tr_df = pd.concat([class_paths, image_names, image_classes], axis=1)\n",
    "    \n",
    "    return tr_df\n",
    "\n",
    "tr_df = train_df('./skin-cancer-dataset/train')\n",
    "print(tr_df)\n",
    "groupped = tr_df.groupby([\"Class\"]).count()\n",
    "print(groupped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe test\n",
    "Obtener todas las imágenes dentro de la carpeta de test y guardar los Path junto con los nombres de las imagenes y si es maligna o benigna en un Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "def test_df(test_path):\n",
    "    classes = [] # Benignas o malignas\n",
    "    class_paths = [] # Ruta a las imagenes\n",
    "    image_names = [] # Nombre de las imagenes\n",
    "\n",
    "    files = os.listdir(test_path) # Archivos\n",
    "    for file in files: \n",
    "        label_dir = os.path.join(test_path, file) # Path del directorio\n",
    "        label = os.listdir(label_dir) # Imagenes dentro del directorio\n",
    "        for image in label:\n",
    "            if not image.startswith('.'):\n",
    "                image_names.append(image) \n",
    "                class_paths.append(label_dir) \n",
    "                classes.append(file) # Añade el nombre del archivo\n",
    "\n",
    "    # Series de pandas\n",
    "    class_paths = pd.Series(class_paths, name='Class Path')\n",
    "    image_names = pd.Series(image_names, name='Image name')\n",
    "    image_classes = pd.Series(classes, name='Class') \n",
    "\n",
    "    # Crea el dataframe\n",
    "    ts_df = pd.concat([class_paths, image_names, image_classes], axis=1)\n",
    "    return ts_df\n",
    "\n",
    "ts_df = test_df('./skin-cancer-dataset/test')\n",
    "print(len(ts_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar los datos entre 0 y 1\n",
    "Normalizar los datos de Benigno y Maligno de string a numeros (0 o 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Class Path Image name  Class\n",
      "0     ./skin-cancer-dataset/train/Malignant     63.jpg      1\n",
      "1     ./skin-cancer-dataset/train/Malignant    823.jpg      1\n",
      "2     ./skin-cancer-dataset/train/Malignant   1409.jpg      1\n",
      "3     ./skin-cancer-dataset/train/Malignant    189.jpg      1\n",
      "4     ./skin-cancer-dataset/train/Malignant     77.jpg      1\n",
      "...                                     ...        ...    ...\n",
      "3994     ./skin-cancer-dataset/train/Benign    190.jpg      0\n",
      "3995     ./skin-cancer-dataset/train/Benign   1404.jpg      0\n",
      "3996     ./skin-cancer-dataset/train/Benign   1410.jpg      0\n",
      "3997     ./skin-cancer-dataset/train/Benign    184.jpg      0\n",
      "3998     ./skin-cancer-dataset/train/Benign   1376.jpg      0\n",
      "\n",
      "[3999 rows x 3 columns]                                 Class Path Image name  Class\n",
      "0     ./skin-cancer-dataset/test/Malignant   6400.jpg      1\n",
      "1     ./skin-cancer-dataset/test/Malignant   6366.jpg      1\n",
      "2     ./skin-cancer-dataset/test/Malignant   6372.jpg      1\n",
      "3     ./skin-cancer-dataset/test/Malignant   6414.jpg      1\n",
      "4     ./skin-cancer-dataset/test/Malignant   5653.jpg      1\n",
      "...                                    ...        ...    ...\n",
      "1995     ./skin-cancer-dataset/test/Benign   6343.jpg      0\n",
      "1996     ./skin-cancer-dataset/test/Benign   6425.jpg      0\n",
      "1997     ./skin-cancer-dataset/test/Benign   7075.jpg      0\n",
      "1998     ./skin-cancer-dataset/test/Benign   7061.jpg      0\n",
      "1999     ./skin-cancer-dataset/test/Benign   6419.jpg      0\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "tr_df['Class'].replace({'Benign': 0, 'Malignant': 1}, inplace=True)\n",
    "ts_df['Class'].replace({'Benign': 0, 'Malignant': 1}, inplace=True) \n",
    "print(tr_df, ts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferenciar los datos\n",
    "### Partir las X Y\n",
    "Indicar al Dataframe train y test cuales son los datos y cuales son los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainX = tr_df.values[:, :-1]\n",
    "trainY = tr_df.values[:, -1]\n",
    "\n",
    "# Test\n",
    "testX = ts_df.values[:, :-1]\n",
    "testY = ts_df.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir les Y en tensor\n",
    "Les X las convertimos despues de obtener la imagen del Path en el Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "trainY = torch.tensor(trainY.astype(int))\n",
    "testY = torch.tensor(testY.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase Dataset\n",
    "Al obtener el dataset devolverá la imagen como tensor, que será la X y los resultados Y.\n",
    "\n",
    "### **Normalizar las imagenes**:\n",
    "Las imágenes están contenidas dentro de X en forma de Path por un lado y el image name por otro. Para ello tenemos que convertir los paths a una imagen y normalizar los datos para que sean entre 0 y 1 en vez de 0 a 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as transform\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.image_path = X[:, 0]\n",
    "        self.image_name = X[:, 1]\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(str(Path(self.image_path[idx]) / self.image_name[idx]))\n",
    "        #print(read_image(self.image_path[idx]))\n",
    "        PIL_image = PIL.Image.open(str(Path(self.image_path[idx]) / self.image_name[idx]))\n",
    "        tensor_image = transform.to_tensor(PIL_image)/255.0 # Convertir a tensor y normalizar\n",
    "        return tensor_image, self.Y[idx] # Lo devuelves directamente como una imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear el propi dataset\n",
    "Passar al train_dataloader i test_dataloader un objecte dataset, nosaltres hem de crear aquet dataset extenent de la clase Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = myDataset(trainX, trainY)\n",
    "test_dataset = myDataset(testX, testY)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear la red neuronal\n",
    "1. Crear el dispositivo\n",
    "2. Definir la clase *Module* con la función forward\n",
    "    - Convulacional (como es en color, cada imagen se multiplica x 3)\n",
    "    - Capas normales \n",
    "3. Crear el modelo y pasarlo a la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Ya están implementadas las clases de las capas para hacer el forward\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # 3 imatges de 224 x 224\n",
    "            nn.Conv2d(3, 30, (8, 8)), # Entrada, salida, filtro\n",
    "            nn.MaxPool2d((4, 4)), \n",
    "\n",
    "            nn.Conv2d(30, 120, (5, 5)), # 120 imatges de 69x76\n",
    "            nn.MaxPool2d((3, 3)), # 120 imatges de 23x25\n",
    "\n",
    "            #nn.Conv2d(120, 240, (3, 3)), # 250 imatges de 19x21\n",
    "            #nn.MaxPool2d((3, 3)), # 250 imatges de 6x7\n",
    "            \n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(30720, 3000), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3000, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x) # Crea las capas\n",
    "        return logits\n",
    "    \n",
    "# Device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = NeuralNetwork().to(device) # Otiene los valores predichos\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train y test\n",
    "Definimos las funciones para train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "def train_loop(train_dataloader, model, loss_fn, optimizer):\n",
    "    size = len(train_dataloader.dataset)\n",
    "\n",
    "    for batch, (X, Y) in enumerate(train_dataloader):\n",
    "        X = X.to(device) \n",
    "        Y = Y.to(device) \n",
    "        \n",
    "        pred = model(X) # Forward, ya ha calculado todos los gradientes\n",
    "        loss = loss_fn(pred, Y) # Crear la función de costo: error\n",
    "\n",
    "        loss.backward() # Le pasa el error al gradiente\n",
    "        optimizer.step() # Actualiza los valores\n",
    "        optimizer.zero_grad() # Pone el gradiente a 0\n",
    "\n",
    "        # Accuracy\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(test_dataloader, model, loss_fn):\n",
    "    size = len(test_dataloader.dataset)\n",
    "    num_batches = len(test_dataloader)\n",
    "    all_preds = torch.tensor([]).to(device)\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # No calcula el gradiente automaticamente\n",
    "    with torch.no_grad():\n",
    "        for X, Y in test_dataloader:\n",
    "            \n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            pred = model(X) # Forward\n",
    "            test_loss += loss_fn(pred, Y).item() # Error\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item() # Accuracy\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all predicted values\n",
    "Of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((all_preds, pred), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# get all the predictions for the entire training set\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_preds\u001b[39m(model, loader):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_preds' is not defined"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "all_preds = torch.cat((all_preds, pred), dim=0) \n",
    "\n",
    "# get all the predictions for the entire training set\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    model.eval() # set model to evaluate mode\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "    \n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m stacked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((Y, pred), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Concatenar\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize a confusion matrix with 0s\u001b[39;00m\n\u001b[1;32m      5\u001b[0m confusion_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "stacked = torch.stack((Y, pred), dim=1) # Concatenar\n",
    "# Initialize a confusion matrix with 0s\n",
    "confusion_matrix = torch.zeros(10, 10, dtype=torch.int32)\n",
    "\n",
    "# fill in the matrix\n",
    "for row in stacked:\n",
    "    true_label, pred_label = row.numpy()\n",
    "    confusion_matrix[true_label, pred_label] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llamar a train y test\n",
    "En cada epoca hacer un train y un test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.710129  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693242 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.689658  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693461 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.691251  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.688960 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.689058  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.640091 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.604699  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.584959 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.618053  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.623358 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.645988  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.543013 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.509122  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.569907 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.594514  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.578416 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.575059  [   64/ 3999]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.526397 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_OpNamespace' 'image' object has no attribute 'read_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m read_image(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/cynthia/Developer/Git/Formación/Dev Git ITIC/Artificial Inteligence/Neural Network/Skin-cancer/skin-cancer-dataset/train/Malignant/63.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torchvision/io/image.py:258\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[1;32m    257\u001b[0m     _log_api_usage_once(read_image)\n\u001b[0;32m--> 258\u001b[0m data \u001b[38;5;241m=\u001b[39m read_file(path)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torchvision/io/image.py:52\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[1;32m     51\u001b[0m     _log_api_usage_once(read_file)\n\u001b[0;32m---> 52\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mread_file(path)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/_ops.py:822\u001b[0m, in \u001b[0;36m_OpNamespace.__getattr__\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m    820\u001b[0m     op, overload_names \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_get_operation(qualified_op_name)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    823\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_OpNamespace\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;66;03m# Turn this into AttributeError so getattr(obj, key, default)\u001b[39;00m\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;66;03m# works (this is called by TorchScript with __origin__)\u001b[39;00m\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    829\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_OpNamespace\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_OpNamespace' 'image' object has no attribute 'read_file'"
     ]
    }
   ],
   "source": [
    "img = read_image(\"/Users/cynthia/Developer/Git/Formación/Dev Git ITIC/Artificial Inteligence/Neural Network/Skin-cancer/skin-cancer-dataset/train/Malignant/63.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
